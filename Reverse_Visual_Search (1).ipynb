{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Note-The code was combinely used on colab and VScode as some of the snippets were working on different IDEs. "
      ],
      "metadata": {
        "id": "HSc8g7fqHNwf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1) Downloading the dataset**"
      ],
      "metadata": {
        "id": "LecRHgPNKIaL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have downloaded whole data in zip format in My Drive"
      ],
      "metadata": {
        "id": "Ky2E5w1OxWja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "tJkN9jOuwp-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip gdrive/My\\ Drive/coco_minitrain_25k.zip\n"
      ],
      "metadata": {
        "id": "5YQ9QsHxxhi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We downloaded the dataset using given link-https://github.com/giddyyupp/coco-minitrain loaded into temporary cloud storage.\n",
        "\n"
      ],
      "metadata": {
        "id": "l4r1I6PRKfxO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2) Peforming object detection via pretrained model**"
      ],
      "metadata": {
        "id": "4VDvuGQbLkiQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You need to download following requirements via the given link- https://drive.google.com/file/d/19nwpRA1c_eJVa9U9eBJjq7OUa-54cLSU/view?usp=sharing which is executed in the given code.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "bEbvaZ6WMGYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing all the requirements at first\n",
        "!pip install -r /content/gdrive/MyDrive/requirement.txt"
      ],
      "metadata": {
        "id": "3ShUD1DuFyjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pixellib\n"
      ],
      "metadata": {
        "id": "9WH9YwFKIQ6o"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: If this code doesn't executes, make sure that runtime is on GPU\n",
        "\n",
        "from pixellib.instance import instance_segmentation\n"
      ],
      "metadata": {
        "id": "iFnP2DcEKruj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finding all the images in the given JSON file"
      ],
      "metadata": {
        "id": "yIAtdcPnNtYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "annotation_file=pd.read_json(r'/content/coco_minitrain_25k/annotations/instances_val2017.json',lines=True)"
      ],
      "metadata": {
        "id": "MqYDlXZ15-CM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Images=annotation_file['images']"
      ],
      "metadata": {
        "id": "WGn1LaHO62x2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "single_info=Images[0]"
      ],
      "metadata": {
        "id": "VGoXMixM7y2d"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "single_info"
      ],
      "metadata": {
        "id": "XNlzvxvHQicR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filenames=[]\n",
        "for i in single_info:\n",
        "  filenames.append(i['file_name'])"
      ],
      "metadata": {
        "id": "-l264oPw8cJB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filenames # This list wil be used in performing Object detection for each images of our dataset."
      ],
      "metadata": {
        "id": "YlOMcZNK_yXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "segment_image = instance_segmentation()\n"
      ],
      "metadata": {
        "id": "es540qFxKuxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pretrained model is required to peform the object detection. It can downloaded via the given link-https://github.com/matterport/Mask_RCNN/releases/tag/v2.0"
      ],
      "metadata": {
        "id": "WbkfW2fAPaiL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the pre-trained model-- Mask RCNN which we will use.\n",
        "segment_image.load_model(\"/content/gdrive/MyDrive/mask_rcnn_coco.h5\") \n"
      ],
      "metadata": {
        "id": "8p2rGyJ2KyaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trying out our pretrained model to perform the detection task on one single image of our dataset to see the output."
      ],
      "metadata": {
        "id": "WEgWms2DPwf3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### It will give outputed image consisting of bounding box in our current working directory by name-'output4.jpg'"
      ],
      "metadata": {
        "id": "h44aCnGlQBZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here a we see 'show_bboxes=True' that will highlight bounding boxes for our case\n",
        "segment_image.segmentImage(\"/content/gdrive/MyDrive/000000000692.jpg\", show_bboxes = True, output_image_name = \"output4.jpg\")"
      ],
      "metadata": {
        "id": "0Wk1B18mQgPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Performing the same step but for each image of our dataset in order to get the bounding boxes in alll of them."
      ],
      "metadata": {
        "id": "L6Ydo2pSQ441"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fileinput import filename\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from datetime import datetime\n",
        "import flask\n",
        "import json\n",
        "import codecs\n",
        "from flask import Flask, request, render_template\n",
        "from pathlib import Path\n",
        "import base64\n",
        "import glob\n",
        "\n",
        "for img in Path(r'/content/coco_minitrain_25k/images/train2017').glob(\"*.json\"):\n",
        "  segment_image.segmentImage(img, show_bboxes = True, output_image_name = \"output.jpg\")\n",
        "\n",
        "  #Path(r\"D:/ImageSearchengine/static/feature\")"
      ],
      "metadata": {
        "id": "MdNhtLZRBe8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As executed above code, we are able to get the bounding boxes for each image in the dataset and those object detected images are automatically downloaded to our temporary google cloud storage."
      ],
      "metadata": {
        "id": "kOcbMYkERhPV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3) Reverse Image Search - Feature Extraction**"
      ],
      "metadata": {
        "id": "r71sEquvTt4f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install feature_extractor\n",
        "from feature_extractor import FeatureExtractor"
      ],
      "metadata": {
        "id": "P1hcvl_mDDeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fe = FeatureExtractor()\n",
        "features = []\n",
        "img_paths = []\n",
        "for feature_path in Path(r\"/content/coco_minitrain_25k/images/train2017\").glob(\"*.json\"):\n",
        "    obj_text=codecs.open(feature_path,'r').read()\n",
        "    features.append(json.loads(obj_text))\n",
        "features = np.array(features)\n"
      ],
      "metadata": {
        "id": "RWbR-9AsYcQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "That's how we get the features out"
      ],
      "metadata": {
        "id": "AaSY2Hwn5NEz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is another method to get features out using a pre built user defined function which is as follows:"
      ],
      "metadata": {
        "id": "KEMHOFYK7dK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_inference_for_single_image(image, graph):\n",
        "    with graph.as_default():\n",
        "        with tf.Session() as sess:\n",
        "            # Get handles to input and output tensors\n",
        "            ops = tf.get_default_graph().get_operations()\n",
        "            all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
        "            tensor_dict = {}\n",
        "            for key in ['num_detections', 'detection_boxes', 'detection_scores', 'detection_classes',\n",
        "                        'detection_masks', 'detection_features']:\n",
        "                tensor_name = key + ':0'\n",
        "                if tensor_name in all_tensor_names:\n",
        "                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name( tensor_name)\n",
        "            if 'detection_masks' in tensor_dict:\n",
        "                # The following processing is only for single image\n",
        "                detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
        "                detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
        "                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
        "                real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
        "                detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
        "                detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
        "                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks( detection_masks, detection_boxes, image.shape[1], image.shape[2])\n",
        "                detection_masks_reframed = tf.cast( tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
        "                # Follow the convention by adding back the batch dimension\n",
        "                tensor_dict['detection_masks'] = tf.expand_dims( detection_masks_reframed, 0)\n",
        "            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "            # Run inference\n",
        "            output_dict = sess.run(tensor_dict, feed_dict={image_tensor: image})\n",
        "\n",
        "            # all outputs are float32 numpy arrays, so convert types as appropriate\n",
        "            output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
        "            output_dict['detection_classes'] = output_dict[ 'detection_classes'][0].astype(np.int64)\n",
        "            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
        "            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
        "            output_dict['detection_features'] = output_dict['detection_features'][0]\n",
        "            if 'detection_masks' in output_dict:\n",
        "                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
        "    return output_dict"
      ],
      "metadata": {
        "id": "QfeSW9a1ToLm"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4) Reverse Image Search - Similarity Search**\n"
      ],
      "metadata": {
        "id": "nspMQMSu78qs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Here we are deciding to use Cosine Similarity Search Metric to execute similarity search."
      ],
      "metadata": {
        "id": "5wDCYKF99aMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity \n"
      ],
      "metadata": {
        "id": "1d_0fUd19Y38"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute cosine similarities between images\n",
        "\n",
        "cosSimilarities = cosine_similarity(features)"
      ],
      "metadata": {
        "id": "iFznOvsEBDrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_closest_images = 5 \n",
        "imgs_model_width = 224\n",
        "imgs_model_height = 224\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "1GKB9VHDBTuT"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_most_similar_products(given_img):\n",
        "\n",
        "  print(\"-----------------------------------------------------------------------\")\n",
        "  print(\"original product:\")\n",
        "\n",
        "  original = image.load_img(given_img, target_size=(imgs_model_width, imgs_model_height))\n",
        "  plt.imshow(original)\n",
        "  plt.show()\n",
        "  print(\"-----------------------------------------------------------------------\")\n",
        "  print(\"most similar products:\")\n",
        "\n",
        "  closest_imgs = cos_similarities_df[given_img].sort_values(ascending=False)[1:nb_closest_images+1].index\n",
        "  closest_imgs_scores = cos_similarities_df[given_img].sort_values(ascending=False)[1:nb_closest_images+1]\n",
        "\n",
        "  for i in range(0,len(closest_imgs)):\n",
        "      original = image.load_img(closest_imgs[i], target_size=(imgs_model_width, imgs_model_height))\n",
        "      plt.imshow(original)\n",
        "      plt.show()\n",
        "      print(\"similarity score : \",closest_imgs_scores[i])"
      ],
      "metadata": {
        "id": "-e6b-Fk7GG1S"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By the above User defined function, you can query the by one image to get similar results."
      ],
      "metadata": {
        "id": "mySLA0bbGTty"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}